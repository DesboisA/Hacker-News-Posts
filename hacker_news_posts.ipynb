{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project, the following data set of submissions to popular technology [site Hacker News](https://news.ycombinator.com/) will be used. \n",
    "\n",
    "Hacker News is a social news website focusing on computer science and entrepreneurship where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit.\n",
    "\n",
    "The dataset can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts) and presents the following informations:\n",
    "\n",
    "`id`: The unique identifier from Hacker News for the post\n",
    "\n",
    "`title`: The title of the post\n",
    "\n",
    "`url`: The URL that the posts links to, if the post has a URL\n",
    "\n",
    "`num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "\n",
    "`num_comments`: The number of comments that were made on the post\n",
    "\n",
    "`author`: The username of the person who submitted the post\n",
    "\n",
    "`created_at`: The date and time at which the post was submitted\n",
    "\n",
    "\n",
    "Posts whose titles begin with either `Ask HN` or `Show HN` will be analysed. Users submit `Ask HN` posts to ask the Hacker News community a specific question and `Show HN` posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "These two types of posts will be compared to determine the following:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "### Import data set ###\n",
    "open_file = open('HN_posts_year_to_Sep_26_2016.csv')\n",
    "read_file = reader(open_file)\n",
    "dataset = list(read_file)\n",
    "\n",
    "dataset_header = dataset[0]\n",
    "hn = dataset[1:]\n",
    "\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to print rows in a readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "\n",
    "print(dataset_header)        \n",
    "print('\\n')\n",
    "explore_data(hn, 0, 5, rows_and_columns=True)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this dataset, posts beginning with `Ask HN` and `Show HN` (and case variations) will be separated into two different lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts that start with ask_hn: 9139\n",
      "Number of posts that start with show_hn: 10158\n",
      "Number of other post types: 273822\n",
      "293119\n"
     ]
    }
   ],
   "source": [
    "ask_posts=[]\n",
    "ask_posts_db=[]\n",
    "\n",
    "show_posts=[]\n",
    "show_posts_db=[]\n",
    "\n",
    "other_posts=[]\n",
    "\n",
    "for row in hn:\n",
    "    title=row[1]\n",
    "    title=title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(title)\n",
    "        ask_posts_db.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(title)\n",
    "        show_posts_db.append(row)\n",
    "    else:\n",
    "        other_posts.append(title)\n",
    "\n",
    "tot = len(ask_posts)+len(show_posts)+len(other_posts)\n",
    "print('Number of posts that start with ask_hn:', len(ask_posts))\n",
    "print('Number of posts that start with show_hn:', len(show_posts))\n",
    "print('Number of other post types:', len(other_posts))\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be determined which ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of comments in ask posts: 94986\n",
      "Average number of comments in ask posts: 10.39\n",
      "\n",
      "\n",
      "Total number of comments in show posts: 49633\n",
      "Average number of comments in show posts: 4.89\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts_db:\n",
    "    clean_row = row[4]\n",
    "    clean_row = clean_row.replace(\"'\",\"\")\n",
    "    clean_row = int(clean_row)\n",
    "    total_ask_comments = total_ask_comments + clean_row\n",
    "\n",
    "for row in show_posts_db:\n",
    "    clean_row = row[4]\n",
    "    clean_row = clean_row.replace(\"'\",\"\")\n",
    "    clean_row = int(clean_row)\n",
    "    total_show_comments = total_show_comments + clean_row\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts) \n",
    "avg_show_comments = total_show_comments / len(show_posts) \n",
    "\n",
    "print('Total number of comments in ask posts:',total_ask_comments)\n",
    "print('Average number of comments in ask posts:',round(avg_ask_comments,2))\n",
    "print('\\n')\n",
    "print('Total number of comments in show posts:',total_show_comments)\n",
    "print('Average number of comments in show posts:',round(avg_show_comments,2))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, ask posts receive more comments on average. Which mean users tend to comment more with posts related to a specific question for the Hacker News community.\n",
    "\n",
    "Since ask posts are more likely to receive comments, it will be determined if ask posts created at a certain time are more likely to attract comments.\n",
    "\n",
    "In the following, two dictionaries will be created:\n",
    "\n",
    "`counts_by_hour`: contains the number of ask posts created during each hour of the day.  \n",
    "`comments_by_hour`: contains the corresponding number of comments ask posts created at each hour received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of ask posts created per hour:\n",
      " [('00', 301), ('01', 282), ('02', 269), ('03', 271), ('04', 243), ('05', 209), ('06', 234), ('07', 226), ('08', 257), ('09', 222), ('10', 282), ('11', 312), ('12', 342), ('13', 444), ('14', 513), ('15', 646), ('16', 579), ('17', 587), ('18', 614), ('19', 552), ('20', 510), ('21', 518), ('22', 383), ('23', 343)]\n",
      "\n",
      "\n",
      "Total amount of comments:\n",
      " [('00', 2277), ('01', 2089), ('02', 2996), ('03', 2154), ('04', 2360), ('05', 1838), ('06', 1587), ('07', 1585), ('08', 2362), ('09', 1477), ('10', 3013), ('11', 2797), ('12', 4234), ('13', 7245), ('14', 4972), ('15', 18525), ('16', 4466), ('17', 5547), ('18', 4877), ('19', 3954), ('20', 4462), ('21', 4500), ('22', 3372), ('23', 2297)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in ask_posts_db:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "datetime_format = \"%m/%d/%Y %H:%M\"\n",
    "for row in result_list:\n",
    "    time = row[0]\n",
    "    comment = row[1]\n",
    "    dt_object = dt.datetime.strptime(time, datetime_format)\n",
    "    dt_hour = dt_object.strftime(\"%H\")\n",
    "    \n",
    "    if dt_hour not in counts_by_hour:\n",
    "        counts_by_hour[dt_hour] = 1\n",
    "        comments_by_hour[dt_hour]= comment\n",
    "    \n",
    "    else:\n",
    "        counts_by_hour[dt_hour] += 1\n",
    "        comments_by_hour[dt_hour] += comment\n",
    "\n",
    "counts_by_hour_items = counts_by_hour.items()\n",
    "sorted_counts_by_hour = sorted(counts_by_hour_items)\n",
    "\n",
    "comments_by_hour_items = comments_by_hour.items()\n",
    "sorted_comments_by_hour = sorted(comments_by_hour_items)\n",
    "\n",
    "print(\"Amount of ask posts created per hour:\\n\", sorted_counts_by_hour)\n",
    "print('\\n')\n",
    "print(\"Total amount of comments:\\n\", sorted_comments_by_hour)\n",
    "print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dictionaries will be used to calculate the average number of comments per post for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_hour = comments_by_hour[hour]/counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, avg_hour])\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.676470588235293, '15'], [16.31756756756757, '13'], [12.380116959064328, '12'], [11.137546468401487, '02'], [10.684397163120567, '10']]\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Comments:\n",
      "\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "sorted_swap= sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(sorted_swap[:5])\n",
    "print(\"\\n\")\n",
    "print(\"Top 5 Hours for Ask Posts Comments:\\n\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1], '%H')\n",
    "    hour = hour.strftime('%H:00')\n",
    "    string = '{h}: {avg:.2f} average comments per post'.format(h = hour, avg = row[0])\n",
    "    print(string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time zone for the dataset is Eastern Time in the US. Let's consider Central European Standard Time such as France which is 6 ahead of Eastern Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00: 28.68 average comments per post\n",
      "19:00: 16.32 average comments per post\n",
      "18:00: 12.38 average comments per post\n",
      "08:00: 11.14 average comments per post\n",
      "16:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1], '%H')\n",
    "    Fr_time = hour + dt.timedelta(hours = 6)\n",
    "    Fr_time = Fr_time.strftime('%H:00')\n",
    "    string = '{h}: {a:.2f} average comments per post'.format(h = Fr_time, a = row[0])\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "\n",
    "A dataset on the Hacker News posts was analysed in order to answer two questions:\n",
    "\n",
    "### - Do Ask HN or Show HN receive more comments on average?\n",
    "Based on the finding results, ask posts receive more comments on average. Which mean users tend to comment more with posts related to a specific question for the Hacker News community.\n",
    "\n",
    "### - Do posts created at a certain time receive more comments on average?\n",
    "Based on the finding results, for the **Eastern Time** a post created at 3pm will receive more comments on average. \n",
    "\n",
    "While for **Central European Standard Time**, a post created at 9pm will receive more comments on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
